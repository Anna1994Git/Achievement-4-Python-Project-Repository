{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1397cde9-c50f-4e10-9f6a-a0e20ecbb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1a9478e-1715-45fc-8bfc-6e7f64be844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   n_dependants fam_status  income  \n",
      "0             3    married  165665  \n",
      "1             0     single   59285  \n",
      "2             2    married   99568  \n",
      "3             0     single   42049  \n",
      "4             1    married   40374  \n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\CareerFoundary\\Achivement 4.9\\data\\Original Data\\customers.csv\"\n",
    "df_customers = pd.read_csv(file_path)\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c1dff5c-2ef4-41bc-957a-b2fbe2c5e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns for Clarity\n",
    "df_customers.rename(columns={\n",
    "    'First Name': 'first_name',\n",
    "    'Surnam': 'last_name',  \n",
    "    'Gender': 'gender',\n",
    "    'STATE': 'state',  \n",
    "    'Age': 'age',\n",
    "    'date_joined': 'date_joined',\n",
    "    'n_dependants': 'num_dependents',  \n",
    "    'fam_status': 'family_status',\n",
    "    'income': 'annual_income'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51bed721-3f3f-4b35-9b0a-e4ecfe6c997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id first_name last_name  gender       state  age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   num_dependents family_status  annual_income  \n",
      "0               3       married         165665  \n",
      "1               0        single          59285  \n",
      "2               2       married          99568  \n",
      "3               0        single          42049  \n",
      "4               1       married          40374  \n"
     ]
    }
   ],
   "source": [
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e427de02-f7d6-45a8-ab7b-9f329ad1a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "df_customers.drop(columns=['first_name', 'last_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07973ca4-b8e4-4085-94a8-8d2bb077d9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           0\n",
      "gender            0\n",
      "state             0\n",
      "age               0\n",
      "date_joined       0\n",
      "num_dependents    0\n",
      "family_status     0\n",
      "annual_income     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values\n",
    "print(df_customers.isnull().sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "911a5ac0-ddad-448e-832b-5e6e1e5a7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data type\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7abb154-1668-4753-9230-31685e29f970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  gender       state  age date_joined  num_dependents family_status  \\\n",
      "0    26711  Female    Missouri   48  2017-01-01               3       married   \n",
      "1    33890  Female  New Mexico   36  2017-01-01               0        single   \n",
      "2    65803    Male       Idaho   35  2017-01-01               2       married   \n",
      "3   125935  Female        Iowa   40  2017-01-01               0        single   \n",
      "4   130797  Female    Maryland   26  2017-01-01               1       married   \n",
      "\n",
      "   annual_income  \n",
      "0         165665  \n",
      "1          59285  \n",
      "2          99568  \n",
      "3          42049  \n",
      "4          40374  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   user_id         206209 non-null  int64         \n",
      " 1   gender          206209 non-null  object        \n",
      " 2   state           206209 non-null  object        \n",
      " 3   age             206209 non-null  int64         \n",
      " 4   date_joined     206209 non-null  datetime64[ns]\n",
      " 5   num_dependents  206209 non-null  int64         \n",
      " 6   family_status   206209 non-null  object        \n",
      " 7   annual_income   206209 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(3)\n",
      "memory usage: 12.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_customers.head())  \n",
    "print(df_customers.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0fd3f97-8880-4caa-83b9-a00957b23944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df_customers.duplicated()\n",
    "print(\"Number of duplicate rows:\", duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04944952-c4c0-4650-84c1-5e4a10f7aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                    int64\n",
      "gender                    object\n",
      "state                     object\n",
      "age                        int64\n",
      "date_joined       datetime64[ns]\n",
      "num_dependents             int64\n",
      "family_status             object\n",
      "annual_income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#check data type\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "361c19fb-d94e-4f69-ad61-6b9ff1a29425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>annual_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103105.000000</td>\n",
       "      <td>49.501646</td>\n",
       "      <td>2018-08-17 03:06:30.029532928</td>\n",
       "      <td>1.499823</td>\n",
       "      <td>94632.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51553.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2017-10-23 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>103105.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2018-08-16 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>154657.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2019-06-10 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>124244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>593901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59527.555167</td>\n",
       "      <td>18.480962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.118433</td>\n",
       "      <td>42473.786988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id            age                    date_joined  \\\n",
       "count  206209.000000  206209.000000                         206209   \n",
       "mean   103105.000000      49.501646  2018-08-17 03:06:30.029532928   \n",
       "min         1.000000      18.000000            2017-01-01 00:00:00   \n",
       "25%     51553.000000      33.000000            2017-10-23 00:00:00   \n",
       "50%    103105.000000      49.000000            2018-08-16 00:00:00   \n",
       "75%    154657.000000      66.000000            2019-06-10 00:00:00   \n",
       "max    206209.000000      81.000000            2020-04-01 00:00:00   \n",
       "std     59527.555167      18.480962                            NaN   \n",
       "\n",
       "       num_dependents  annual_income  \n",
       "count   206209.000000  206209.000000  \n",
       "mean         1.499823   94632.852548  \n",
       "min          0.000000   25903.000000  \n",
       "25%          0.000000   59874.000000  \n",
       "50%          1.000000   93547.000000  \n",
       "75%          3.000000  124244.000000  \n",
       "max          3.000000  593901.000000  \n",
       "std          1.118433   42473.786988  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd03ad69-cc3c-48fe-9e0f-444123dd6b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " user_id             0\n",
      "First Name      11259\n",
      "Surnam              0\n",
      "Gender              0\n",
      "STATE               0\n",
      "Age                 0\n",
      "date_joined         0\n",
      "n_dependants        0\n",
      "fam_status          0\n",
      "income              0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "Data Types Before Conversion:\n",
      " user_id          int64\n",
      "First Name      object\n",
      "Surnam          object\n",
      "Gender          object\n",
      "STATE           object\n",
      "Age              int64\n",
      "date_joined     object\n",
      "n_dependants     int64\n",
      "fam_status      object\n",
      "income           int64\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_joined\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_joined\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Convert age and annual_income to numeric if needed\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannual_income\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_customers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannual_income\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Check data types again after conversion\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the customer data\n",
    "df_customers = pd.read_csv(r\"C:\\CareerFoundary\\Achivement 4.9\\data\\Original Data\\customers.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\", df_customers.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_rows = df_customers[df_customers.duplicated()]\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n",
    "\n",
    "# Remove duplicates if found\n",
    "df_customers = df_customers.drop_duplicates()\n",
    "\n",
    "# Check data types\n",
    "print(\"Data Types Before Conversion:\\n\", df_customers.dtypes)\n",
    "\n",
    "# Convert date_joined to datetime format\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'], errors='coerce')\n",
    "\n",
    "# Convert age and annual_income to numeric if needed\n",
    "df_customers['age'] = pd.to_numeric(df_customers['age'], errors='coerce')\n",
    "df_customers['annual_income'] = pd.to_numeric(df_customers['annual_income'], errors='coerce')\n",
    "\n",
    "# Check data types again after conversion\n",
    "print(\"Data Types After Conversion:\\n\", df_customers.dtypes)\n",
    "\n",
    "# Get summary statistics to check for outliers\n",
    "print(\"Summary Statistics:\\n\", df_customers.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bd73adf-25cb-404e-ab17-2eb5d2ac4974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'First Name', 'Surnam', 'Gender', 'STATE', 'Age',\n",
      "       'date_joined', 'n_dependants', 'fam_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names to ensure there are no issues with spaces or typos\n",
    "print(df_customers.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74f57a7a-be7a-468b-b22e-d9f28fa29b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'first_name', 'surname', 'Gender', 'state', 'age',\n",
      "       'date_joined', 'num_dependents', 'family_status', 'annual_income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for consistency and standardization\n",
    "df_customers.rename(columns={\n",
    "    'First Name': 'first_name',\n",
    "    'Surnam': 'surname',\n",
    "    'Age': 'age',\n",
    "    'STATE': 'state',\n",
    "    'n_dependants': 'num_dependents',\n",
    "    'fam_status': 'family_status',\n",
    "    'income': 'annual_income'\n",
    "}, inplace=True)\n",
    "\n",
    "# Strip any extra spaces from the column names\n",
    "df_customers.columns = df_customers.columns.str.strip()\n",
    "\n",
    "# Check the updated column names\n",
    "print(df_customers.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a630ec0-2755-4ef4-b8c0-8cdfaf554ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Columns:\n",
      " Index(['user_id', 'first_name', 'surname', 'gender', 'state', 'age',\n",
      "       'date_joined', 'num_dependents', 'family_status', 'annual_income'],\n",
      "      dtype='object')\n",
      "Missing Values:\n",
      " user_id               0\n",
      "first_name        11259\n",
      "surname               0\n",
      "gender                0\n",
      "state                 0\n",
      "age                   0\n",
      "date_joined           0\n",
      "num_dependents        0\n",
      "family_status         0\n",
      "annual_income         0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "Data Types After Conversion:\n",
      " user_id                    int64\n",
      "first_name                object\n",
      "surname                   object\n",
      "gender                    object\n",
      "state                     object\n",
      "age                        int64\n",
      "date_joined       datetime64[ns]\n",
      "num_dependents             int64\n",
      "family_status             object\n",
      "annual_income              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_customers = pd.read_csv(r\"C:\\CareerFoundary\\Achivement 4.9\\data\\Original Data\\customers.csv\")\n",
    "\n",
    "# Rename columns \n",
    "df_customers.rename(columns={\n",
    "    'First Name': 'first_name',\n",
    "    'Surnam': 'surname',\n",
    "    'Age': 'age',\n",
    "    'STATE': 'state',\n",
    "    'n_dependants': 'num_dependents',\n",
    "    'fam_status': 'family_status',\n",
    "    'income': 'annual_income',\n",
    "    'Gender': 'gender'  \n",
    "}, inplace=True)\n",
    "\n",
    "# Strip any extra spaces from the column names\n",
    "df_customers.columns = df_customers.columns.str.strip()\n",
    "\n",
    "# Check the updated column names\n",
    "print(\"Updated Columns:\\n\", df_customers.columns)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\", df_customers.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df_customers[df_customers.duplicated()]\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n",
    "\n",
    "# Remove duplicates if found\n",
    "df_customers = df_customers.drop_duplicates()\n",
    "\n",
    "# Convert 'date_joined' to datetime format\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'], errors='coerce')\n",
    "\n",
    "# Convert 'age' and 'annual_income' to numeric \n",
    "df_customers['age'] = pd.to_numeric(df_customers['age'], errors='coerce')\n",
    "df_customers['annual_income'] = pd.to_numeric(df_customers['annual_income'], errors='coerce')\n",
    "\n",
    "# Check data types again after conversion\n",
    "print(\"Data Types After Conversion:\\n\", df_customers.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c009723d-29b5-4528-a2e5-d1b9018bf506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0   2539329        1    prior             1          2                  8   \n",
      "1   2539329        1    prior             1          2                  8   \n",
      "2   2539329        1    prior             1          2                  8   \n",
      "3   2539329        1    prior             1          2                  8   \n",
      "4   2539329        1    prior             1          2                  8   \n",
      "\n",
      "   days_since_prior_order  product_id  add_to_cart_order  reordered  ...  \\\n",
      "0                     0.0       196.0                1.0        0.0  ...   \n",
      "1                     0.0     14084.0                2.0        0.0  ...   \n",
      "2                     0.0     12427.0                3.0        0.0  ...   \n",
      "3                     0.0     26088.0                4.0        0.0  ...   \n",
      "4                     0.0     26405.0                5.0        0.0  ...   \n",
      "\n",
      "  order_frequency_flag First Name  Surnam  Gender    STATE Age date_joined  \\\n",
      "0     Regular customer      Linda  Nguyen  Female  Alabama  31   2/17/2019   \n",
      "1     Regular customer      Linda  Nguyen  Female  Alabama  31   2/17/2019   \n",
      "2     Regular customer      Linda  Nguyen  Female  Alabama  31   2/17/2019   \n",
      "3     Regular customer      Linda  Nguyen  Female  Alabama  31   2/17/2019   \n",
      "4     Regular customer      Linda  Nguyen  Female  Alabama  31   2/17/2019   \n",
      "\n",
      "  n_dependants fam_status income  \n",
      "0            3    married  40423  \n",
      "1            3    married  40423  \n",
      "2            3    married  40423  \n",
      "3            3    married  40423  \n",
      "4            3    married  40423  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the prepared Instacart data\n",
    "ords_prods_merge = pd.read_pickle(r'C:\\CareerFoundary\\Achivement 4.9\\data\\Prepared Data\\ords_prods_merge.pkl')\n",
    "\n",
    "# Load the customer data (assuming it's already been cleaned and pre-processed)\n",
    "df_customers = pd.read_csv(r'C:\\CareerFoundary\\Achivement 4.9\\data\\Original Data\\customers.csv')\n",
    "\n",
    "# Ensure 'user_id' column is of the same type in both dataframes \n",
    "df_customers['user_id'] = df_customers['user_id'].astype(int)\n",
    "ords_prods_merge['user_id'] = ords_prods_merge['user_id'].astype(int)\n",
    "\n",
    "# Merge the two dataframes on the 'user_id' column\n",
    "combined_data = pd.merge(ords_prods_merge, df_customers, on='user_id', how='left')\n",
    "print(combined_data.head())\n",
    "combined_data.to_pickle(r'C:\\CareerFoundary\\Achivement 4.9\\data\\Prepared Data\\combined_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2c0cc51-01ac-48aa-9b58-f1d86ae6bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved as a pickle file.\n"
     ]
    }
   ],
   "source": [
    "# Export the combined dataframe as a pickle file\n",
    "combined_data.to_pickle(r'C:\\CareerFoundary\\Achivement 4.9\\data\\Prepared Data\\combined_data.pkl')\n",
    "print(\"Combined data saved as a pickle file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff46bc5-1f0f-41c1-ad1a-6a4e374ad66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
